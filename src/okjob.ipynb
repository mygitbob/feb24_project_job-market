{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_host = '127.0.0.1'\n",
    "mongo_port = '27017'\n",
    "mongo_db = 'raw_data'\n",
    "connection_string = f\"mongodb://{mongo_host}:{mongo_port}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'okjob_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(connection_string)\n",
    "db = client[mongo_db]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('661ebfe686c81b1febea47f5'),\n",
       " 'Company-ID': '1810',\n",
       " 'LinkedIn-Job-Link': 'https://www.linkedin.com/jobs/view/strategic-account-executive-at-signifyd-3762391942',\n",
       " 'Company-Name': 'Signifyd',\n",
       " 'Job-Title': 'Strategic Account Executive',\n",
       " 'Location': 'USA',\n",
       " 'Job-Description': 'data/processed/okjob.io/full_job_description/okjob_jobdesc_id=3762391942.html',\n",
       " 'Apply-Link': 'https://www.linkedin.com/jobs/view/3762391942/',\n",
       " 'Region': 'North America',\n",
       " 'Job-Type': 'Remote,100% Salary, Four Days',\n",
       " 'Job-Tags': 'eCommerce, SaaS, RiskManagement, SalesStrategy, BusinessAnalytics',\n",
       " 'Job-Category': 'Sales & Account Management, Business Development',\n",
       " 'Hours': '32',\n",
       " 'Salary-Min': '160000',\n",
       " 'Salary-Max': '185000',\n",
       " 'sourceId': '3762391942'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(db['okjob_test'].find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinkedIn-Job-Link</th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job-Type</th>\n",
       "      <th>Job-Tags</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>Salary-Min</th>\n",
       "      <th>Salary-Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://uk.linkedin.com/jobs/view/junior-data-...</td>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "      <td>Hybrid, Remote, Four Days</td>\n",
       "      <td>SQL, ETL, Python, Kafka, BigQuery</td>\n",
       "      <td>3790819042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://uk.linkedin.com/jobs/view/catalogue-da...</td>\n",
       "      <td>Catalogue Data Analyst</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "      <td>Hybrid, Remote, Four Days</td>\n",
       "      <td>SQL, DataGovernance, DataWarehousing, Metadata...</td>\n",
       "      <td>3791431753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mx.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>Hybrid, 100% Salary, Four Days</td>\n",
       "      <td>Python, Java, SQL, Machine Learning, Data Anal...</td>\n",
       "      <td>3795251305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "      <td>Hybrid, 100% Salary, Four Days</td>\n",
       "      <td>Python, Java, SQL, Machine Learning, Data Anal...</td>\n",
       "      <td>3795248714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Remote, 100% Salary, Four Days</td>\n",
       "      <td>SQL, Python, BigQuery, Dataflow, Airflow</td>\n",
       "      <td>3755031443</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   LinkedIn-Job-Link               Job-Title  \\\n",
       "0  https://uk.linkedin.com/jobs/view/junior-data-...    Junior Data Engineer   \n",
       "1  https://uk.linkedin.com/jobs/view/catalogue-da...  Catalogue Data Analyst   \n",
       "2  https://mx.linkedin.com/jobs/view/data-scienti...  Data Scientist - LATAM   \n",
       "3  https://br.linkedin.com/jobs/view/data-scienti...  Data Scientist - LATAM   \n",
       "4  https://www.linkedin.com/jobs/view/data-engine...           Data Engineer   \n",
       "\n",
       "                                     Location                        Job-Type  \\\n",
       "0  Framwellgate Moor, England, United Kingdom       Hybrid, Remote, Four Days   \n",
       "1  Framwellgate Moor, England, United Kingdom       Hybrid, Remote, Four Days   \n",
       "2                         Mexico City, Mexico  Hybrid, 100% Salary, Four Days   \n",
       "3                São Paulo, São Paulo, Brazil  Hybrid, 100% Salary, Four Days   \n",
       "4                               United States  Remote, 100% Salary, Four Days   \n",
       "\n",
       "                                            Job-Tags    sourceId  Salary-Min  \\\n",
       "0                  SQL, ETL, Python, Kafka, BigQuery  3790819042         NaN   \n",
       "1  SQL, DataGovernance, DataWarehousing, Metadata...  3791431753         NaN   \n",
       "2  Python, Java, SQL, Machine Learning, Data Anal...  3795251305         NaN   \n",
       "3  Python, Java, SQL, Machine Learning, Data Anal...  3795248714         NaN   \n",
       "4           SQL, Python, BigQuery, Dataflow, Airflow  3755031443     98000.0   \n",
       "\n",
       "   Salary-Max  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4     98100.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "    \"$and\": [\n",
    "        {\"sourceId\": {\"$ne\": \"\"}},\n",
    "        {\"Job-Title\": {\"$regex\": \"data\", \"$options\": \"i\"}},  # Case-insensitive search for \"data\" in jobTitle\n",
    "        {\"Location\": {\"$ne\": \"\"}},\n",
    "        {\"Salary-Min\": {\"$ne\": \"\"}},\n",
    "        {\"Salary-Max\": {\"$ne\": \"\"}},\n",
    "        {\"LinkedIn-Job-Link\": {\"$ne\": \"\"}},\n",
    "        {\"Job-Type\": {\"$ne\": \"\"}},\n",
    "        {\"Job-Tags\": {\"$ne\": \"\"}}\n",
    "      # {\"currency\": {\"$ne\": \"\"}}\n",
    "    ]\n",
    "}\n",
    "projection = {\n",
    "    \"sourceId\": 1,\n",
    "    \"Job-Title\": 1,\n",
    "    \"Location\": 1,\n",
    "    \"Salary-Min\": 1,\n",
    "    \"Salary-Max\": 1,\n",
    "    \"LinkedIn-Job-Link\": 1,\n",
    "    \"Job-Type\": 1,\n",
    "    \"Job-Tags\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "documents = collection.find(query, projection)\n",
    "data_objects = []\n",
    "for doc in documents:\n",
    "    data_objects.append(doc)\n",
    "df_ok = pd.DataFrame(data_objects)\n",
    "df_ok['Salary-Min'] = pd.to_numeric(df_ok['Salary-Min'], errors='coerce')\n",
    "df_ok['Salary-Max'] = pd.to_numeric(df_ok['Salary-Max'], errors='coerce')\n",
    "# didn't dropna or filter salary-min, otherwise the dataset is very small, we should fill them with mean/mode later\n",
    "df_ok.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok['Salary-Min'] = df_ok['Salary-Min'].fillna(df_ok['Salary-Min'].mean())\n",
    "df_ok['Salary-Max'] = df_ok['Salary-Max'].fillna(df_ok['Salary-Max'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinkedIn-Job-Link</th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job-Type</th>\n",
       "      <th>Job-Tags</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>Salary-Min</th>\n",
       "      <th>Salary-Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://uk.linkedin.com/jobs/view/junior-data-...</td>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "      <td>Hybrid, Remote, Four Days</td>\n",
       "      <td>SQL, ETL, Python, Kafka, BigQuery</td>\n",
       "      <td>3790819042</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://uk.linkedin.com/jobs/view/catalogue-da...</td>\n",
       "      <td>Catalogue Data Analyst</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "      <td>Hybrid, Remote, Four Days</td>\n",
       "      <td>SQL, DataGovernance, DataWarehousing, Metadata...</td>\n",
       "      <td>3791431753</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mx.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>Hybrid, 100% Salary, Four Days</td>\n",
       "      <td>Python, Java, SQL, Machine Learning, Data Anal...</td>\n",
       "      <td>3795251305</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "      <td>Hybrid, 100% Salary, Four Days</td>\n",
       "      <td>Python, Java, SQL, Machine Learning, Data Anal...</td>\n",
       "      <td>3795248714</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Remote, 100% Salary, Four Days</td>\n",
       "      <td>SQL, Python, BigQuery, Dataflow, Airflow</td>\n",
       "      <td>3755031443</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   LinkedIn-Job-Link               Job-Title  \\\n",
       "0  https://uk.linkedin.com/jobs/view/junior-data-...    Junior Data Engineer   \n",
       "1  https://uk.linkedin.com/jobs/view/catalogue-da...  Catalogue Data Analyst   \n",
       "2  https://mx.linkedin.com/jobs/view/data-scienti...  Data Scientist - LATAM   \n",
       "3  https://br.linkedin.com/jobs/view/data-scienti...  Data Scientist - LATAM   \n",
       "4  https://www.linkedin.com/jobs/view/data-engine...           Data Engineer   \n",
       "\n",
       "                                     Location                        Job-Type  \\\n",
       "0  Framwellgate Moor, England, United Kingdom       Hybrid, Remote, Four Days   \n",
       "1  Framwellgate Moor, England, United Kingdom       Hybrid, Remote, Four Days   \n",
       "2                         Mexico City, Mexico  Hybrid, 100% Salary, Four Days   \n",
       "3                São Paulo, São Paulo, Brazil  Hybrid, 100% Salary, Four Days   \n",
       "4                               United States  Remote, 100% Salary, Four Days   \n",
       "\n",
       "                                            Job-Tags    sourceId  Salary-Min  \\\n",
       "0                  SQL, ETL, Python, Kafka, BigQuery  3790819042     98000.0   \n",
       "1  SQL, DataGovernance, DataWarehousing, Metadata...  3791431753     98000.0   \n",
       "2  Python, Java, SQL, Machine Learning, Data Anal...  3795251305     98000.0   \n",
       "3  Python, Java, SQL, Machine Learning, Data Anal...  3795248714     98000.0   \n",
       "4           SQL, Python, BigQuery, Dataflow, Airflow  3755031443     98000.0   \n",
       "\n",
       "   Salary-Max  \n",
       "0     98100.0  \n",
       "1     98100.0  \n",
       "2     98100.0  \n",
       "3     98100.0  \n",
       "4     98100.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize job titles\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def categorize_seniority(job_title):\n",
    "    doc = nlp(job_title)\n",
    "    # List of keywords (lemmas) to look for\n",
    "    keywords_senior = ['strategic', 'principal', 'staff', 'lead', 'senior', 'head']\n",
    "    keywords_junior = ['trainee', 'junior', 'apprentice', 'entry level' ]\n",
    "    # Check if any token's lemma is in our keywords list\n",
    "    if any(token.lemma_.lower() in keywords_senior for token in doc):\n",
    "        return 'Senior'\n",
    "    elif any(token.lemma_.lower() in keywords_junior for token in doc):\n",
    "        return 'Junior'\n",
    "    else:\n",
    "        return 'Any'\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df_ok['jobLevel'] = df_ok['Job-Title'].apply(categorize_seniority)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your lists of skills, technologies, and site preferences\n",
    "\n",
    "keywords_skills = [\n",
    "    \"SQL\", \"Structured Query Language\", \"Python\", \"R\", \"Docker\", \"AWS\", \"Amazon Web Services\",\n",
    "    \"Azure\", \"Google Cloud Platform\", \"GCP\", \"Snowflake\", \"Hadoop\", \"Spark\", \"Kubernetes\",\n",
    "    \"Jenkins\", \"BI\", \"Business Intelligence\", \"Tableau\", \"Power BI\", \"Looker\", \"ETL\",\n",
    "    \"Extract Transform Load\", \"Informatica\", \"Talend\", \"SSIS\", \"CRM\",\n",
    "    \"Customer Relationship Management\", \"Salesforce\", \"SAP\", \"Git\", \"NoSQL\", \"MongoDB\",\n",
    "    \"Cassandra\", \"PostgreSQL\", \"MySQL\", \"Data Modeling\", \"Machine Learning\", \"ML\", \"AI\",\n",
    "    \"Apache Kafka\", \"Redis\", \"Elasticsearch\", \"Kibana\", \"Ansible\", \"REST\", \"RESTful\", \"API\",\n",
    "    \"GraphQL\", \"Linux\", \"Matplotlib\", \"Seaborn\", \"Jupyter Notebook\", \"Scikit-learn\",\n",
    "    \"TensorFlow\", \"PyTorch\", \"Data Lakes\", \"Data Warehousing\", \"Agile\", \"Scrum\", \"Blockchain\",\n",
    "    \"Edge Computing\", \"VMware\", \"SAS\", \"Flask\", \"Django\", \"Apache\", \"Airflow\", \"Luigi\", \"NLP\",\n",
    "    \"Databricks\", \"redshift\", \"Excel\", \"HANA\", \"Oracle\", \"crypto\"\n",
    "]\n",
    "\n",
    "keywords_site = ['remote', 'hybrid', 'on-site']\n",
    "# Function to categorize job titles and descriptions by keywords, accepting a keyword list as a parameter\n",
    "def categorize_by_keywords(text, keywords):\n",
    "    doc = nlp(text)\n",
    "    # Initialize an empty set to avoid duplicates\n",
    "    keywords_found = set()\n",
    "    # Check each token in the text\n",
    "    for token in doc:\n",
    "        # Normalize the token's text for case-insensitive matching\n",
    "        token_text = token.text.lower()\n",
    "        # If the normalized token is in our list of keywords, add the original token text to the set\n",
    "        if token_text in [keyword.lower() for keyword in keywords]:\n",
    "            keywords_found.add(token.text)\n",
    "    # Return a comma-separated string of unique keywords found, or \"None\" if no keywords were identified\n",
    "    return ', '.join(keywords_found) if keywords_found else \"None\"\n",
    "\n",
    "# Applying the function to each row for both jobSkills and jobSite columns\n",
    "df_ok['jobSkills'] = df_ok.apply(lambda row: categorize_by_keywords(row['Job-Type'] + \" \" + row['Job-Tags'], keywords_skills), axis=1)\n",
    "df_ok['jobSite'] = df_ok.apply(lambda row: categorize_by_keywords(row['Job-Type'] + \" \" + row['Job-Tags'], keywords_site), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize titles\n",
    "keywords_title = {\n",
    "    \"data administrator\": [\"data\", \"administrator\", \"entry\", \"protection\", \"officer\", \"clerk\", \"admin\", \"migration\", \"cleanser\", \"inputter\", \"coordinator\", \"assistant\", \"pocessor\", \"auditor\", \"governance\", \"apprentice\", \"executive\", \"manager\"],\n",
    "    \"data engineer\": [\"data\", \"engineer\", \"developer\", \"engineering\", \"modeller\", \"technical\"],\n",
    "    \"data analyst\": [\"data\", \"analyst\", \"analytics\", \"analysis\", \"investigation\", \"workstream\", \"visualisation\", \"insight\", \"consultant\"],\n",
    "    \"database administrator\": [\"database\", \"administrator\", \"assistant\", \"manager\"],\n",
    "    \"data scientist\": [\"data\", \"scientist\", \"science\", \"engineer\"],\n",
    "    \"data center\": [\"data\", \"center\", \"cabling\", \"installer\", \"installation\", \"engineer\"],\n",
    "    \"data test\": [\"data\", \"test\", \"tester\", \"automation\", \"processing\"],\n",
    "    \"data architect\": [\"data\", \"architect\"],\n",
    "    \"manager\": [\"head\", \"manager\", \"director\", \"procurement\", \"management\"]  \n",
    "}\n",
    "def categorize_job_titles(job_title, keywords_title):\n",
    "    # Prepare the job title: lowercase, remove special characters, and split into words\n",
    "    words = re.sub('[^a-z0-9\\s]', '', job_title.lower()).split()\n",
    "    \n",
    "    # Initialize a dictionary to hold the count of matches for each category\n",
    "    matches = defaultdict(int)\n",
    "    # Initialize a dictionary to hold the sum of indexes for matched words for tie-breaking\n",
    "    index_sums = defaultdict(int)\n",
    "    \n",
    "    for category, keywords in keywords_title.items():\n",
    "        for word in words:\n",
    "            if word in keywords:\n",
    "                matches[category] += 1\n",
    "                # Sum the indexes of matched words for tie-breaking\n",
    "                index_sums[category] += keywords.index(word)\n",
    "    \n",
    "    if not matches:\n",
    "        return 'Other'\n",
    "    \n",
    "    # Find the category(ies) with the maximum count of matches\n",
    "    max_matches = max(matches.values())\n",
    "    candidates = [category for category, count in matches.items() if count == max_matches]\n",
    "    \n",
    "    # If there's a single best match, return it\n",
    "    if len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "    \n",
    "    # If there are ties, use the sum of indexes for tie-breaking\n",
    "    return min(candidates, key=lambda category: index_sums[category])\n",
    "# Apply the function to the 'jobTitle' column and create a new 'jobCategory' column\n",
    "df_ok['jobCategory'] = df_ok['Job-Title'].apply(lambda x: categorize_job_titles(x, keywords_title))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok = df_ok[['jobCategory', 'jobLevel', 'jobSkills', 'jobSite', 'Salary-Min', 'Salary-Max', 'sourceId','Job-Title','LinkedIn-Job-Link','Location' ]]\n",
    "df_ok.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sort_and_deduplicate(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # Lowercase, strip whitespace, and split on commas\n",
    "    parts = text.lower().strip().split(',')\n",
    "    # Remove duplicates and sort\n",
    "    cleaned_parts = sorted(set(part.strip() for part in parts))\n",
    "    # Join the cleaned parts back into a single string\n",
    "    return ', '.join(cleaned_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the modified function to sort the terms within the 'jobSite' column using .loc\n",
    "df_ok.loc[:, 'jobSite'] = df_ok['jobSite'].apply(clean_sort_and_deduplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>skills</th>\n",
       "      <th>job_site</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>source_id</th>\n",
       "      <th>job_title_name</th>\n",
       "      <th>joboffer_url</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>Junior</td>\n",
       "      <td>ETL, SQL, Python</td>\n",
       "      <td>hybrid, remote</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>3790819042</td>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>https://uk.linkedin.com/jobs/view/junior-data-...</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>Any</td>\n",
       "      <td>SQL</td>\n",
       "      <td>hybrid, remote</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>3791431753</td>\n",
       "      <td>Catalogue Data Analyst</td>\n",
       "      <td>https://uk.linkedin.com/jobs/view/catalogue-da...</td>\n",
       "      <td>Framwellgate Moor, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>Any</td>\n",
       "      <td>SQL, Python</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>3795251305</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>Any</td>\n",
       "      <td>SQL, Python</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>3795248714</td>\n",
       "      <td>Data Scientist - LATAM</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>Any</td>\n",
       "      <td>SQL, Python, Airflow</td>\n",
       "      <td>remote</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>3755031443</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       categories experience_level                skills        job_site  \\\n",
       "0   data engineer           Junior      ETL, SQL, Python  hybrid, remote   \n",
       "1    data analyst              Any                   SQL  hybrid, remote   \n",
       "2  data scientist              Any           SQL, Python          hybrid   \n",
       "3  data scientist              Any           SQL, Python          hybrid   \n",
       "4   data engineer              Any  SQL, Python, Airflow          remote   \n",
       "\n",
       "   salary_min  salary_max   source_id          job_title_name  \\\n",
       "0     98000.0     98100.0  3790819042    Junior Data Engineer   \n",
       "1     98000.0     98100.0  3791431753  Catalogue Data Analyst   \n",
       "2     98000.0     98100.0  3795251305  Data Scientist - LATAM   \n",
       "3     98000.0     98100.0  3795248714  Data Scientist - LATAM   \n",
       "4     98000.0     98100.0  3755031443           Data Engineer   \n",
       "\n",
       "                                        joboffer_url  \\\n",
       "0  https://uk.linkedin.com/jobs/view/junior-data-...   \n",
       "1  https://uk.linkedin.com/jobs/view/catalogue-da...   \n",
       "2  https://mx.linkedin.com/jobs/view/data-scienti...   \n",
       "3  https://br.linkedin.com/jobs/view/data-scienti...   \n",
       "4  https://www.linkedin.com/jobs/view/data-engine...   \n",
       "\n",
       "                             location_country  \n",
       "0  Framwellgate Moor, England, United Kingdom  \n",
       "1  Framwellgate Moor, England, United Kingdom  \n",
       "2                         Mexico City, Mexico  \n",
       "3                São Paulo, São Paulo, Brazil  \n",
       "4                               United States  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping of source column names to postgres db column names\n",
    "column_mappings = {\n",
    "    'sourceId': 'source_id',\n",
    "    'Job-Title': 'job_title_name',\n",
    "    'jobLevel': 'experience_level',\n",
    "    'Salary-Min': 'salary_min',\n",
    "    'Salary-Max': 'salary_max',\n",
    "    'LinkedIn-Job-Link': 'joboffer_url',\n",
    "    'Location': 'location_country',\n",
    "    'jobSite': 'job_site',\n",
    "    'jobSkills': 'skills',\n",
    "    'jobCategory': 'categories'\n",
    "}\n",
    "additional_columns = {\n",
    "    'data_source_name': 'ok'\n",
    "}\n",
    "# Rename columns based on the mapping\n",
    "df_ok.rename(columns=column_mappings, inplace=True)\n",
    "df_ok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok_postgres = df_ok[\n",
    "    [column_mappings.get(col, col) for col in column_mappings.keys()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/t42qr2k15v3b0fnfl840bhjh0000gn/T/ipykernel_41916/3282893265.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok_postgres[col] = default_value\n"
     ]
    }
   ],
   "source": [
    "# Add additional columns with default values\n",
    "for col, default_value in additional_columns.items():\n",
    "    df_ok_postgres[col] = default_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/t42qr2k15v3b0fnfl840bhjh0000gn/T/ipykernel_41916/3841136033.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok_postgres['salary_min'] = pd.to_numeric(df_ok_postgres['salary_min'], errors='coerce').fillna(0).astype(int)\n",
      "/var/folders/9p/t42qr2k15v3b0fnfl840bhjh0000gn/T/ipykernel_41916/3841136033.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok_postgres['salary_max'] = pd.to_numeric(df_ok_postgres['salary_max'], errors='coerce').fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Ensure salaries are integers and greater than 0\n",
    "df_ok_postgres['salary_min'] = pd.to_numeric(df_ok_postgres['salary_min'], errors='coerce').fillna(0).astype(int)\n",
    "df_ok_postgres['salary_max'] = pd.to_numeric(df_ok_postgres['salary_max'], errors='coerce').fillna(0).astype(int)\n",
    "df_ok_postgres = df_ok_postgres[(df_ok_postgres['salary_min'] > 0) & (df_ok_postgres['salary_max'] > 0)]\n",
    "# Set the types for other fields as strings\n",
    "df_ok_postgres['source_id'] = df_ok_postgres['source_id'].astype(str)\n",
    "df_ok_postgres['experience_level'] = df_ok_postgres['experience_level'].astype(str)\n",
    "df_ok_postgres['joboffer_url'] = df_ok_postgres['joboffer_url'].astype(str)\n",
    "df_ok_postgres['currency_symbol'] = df_ok_postgres['currency_symbol'].astype(str)\n",
    "df_ok_postgres['location_country'] = df_ok_postgres['location_country'].astype(str)\n",
    "df_ok_postgres['data_source_name'] = df_ok_postgres['data_source_name'].astype(str)\n",
    "df_ok_postgres['skills'] = df_ok_postgres['skills'].astype(list)\n",
    "df_ok_postgres['categories'] = df_ok_postgres['categories'].astype(list)\n",
    "df_ok_postgres['job_site'] = df_ok_postgres['job_site'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for currency and publoished date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
